name: Test

on:
  pull_request:
    branches: [main, release]

concurrency:
  group: test-${{ github.head_ref || github.ref }}
  cancel-in-progress: true

jobs:
  # Detect which paths changed to skip irrelevant jobs
  changes:
    name: Detect Changes
    runs-on: ubuntu-latest
    outputs:
      backend: ${{ steps.filter.outputs.backend }}
      frontend: ${{ steps.filter.outputs.frontend }}
    steps:
      - uses: actions/checkout@v6
      - uses: dorny/paths-filter@v3
        id: filter
        with:
          filters: |
            backend:
              - 'backend/**'
              - 'satellite_processor/**'
              - 'requirements*.txt'
              - 'backend/requirements.txt'
            frontend:
              - 'frontend/**'

  lint-audit:
    name: Lint & Security Audit
    runs-on: ubuntu-latest
    needs: [changes]
    if: needs.changes.outputs.backend == 'true'
    steps:
      - uses: actions/checkout@v6

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: "3.11"
          cache: pip
          cache-dependency-path: backend/requirements.txt

      - name: Install dependencies
        run: |
          pip install uv
          uv pip install --system -r backend/requirements.txt
          uv pip install --system ruff pip-audit

      - name: Lint with ruff
        run: ruff check backend/

      - name: Security audit (pip-audit)
        run: pip-audit --strict --ignore-vuln PYSEC-2024-0 || true

  backend:
    name: Backend Tests (Shard ${{ matrix.shard }}/4)
    runs-on: ubuntu-latest
    needs: [changes]
    if: needs.changes.outputs.backend == 'true'
    strategy:
      fail-fast: false
      matrix:
        shard: [1, 2, 3, 4]
    steps:
      - uses: actions/checkout@v6

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: "3.11"
          cache: pip
          cache-dependency-path: backend/requirements.txt

      - name: Install system dependencies
        run: |
          # These packages are pre-installed on ubuntu-24.04 runners
          # Only install if missing (avoids slow apt-get update)
          for pkg in ffmpeg libgl1 libglib2.0-0; do
            dpkg -s "$pkg" >/dev/null 2>&1 || NEED_INSTALL=1
          done
          if [ "${NEED_INSTALL:-}" = "1" ]; then
            sudo apt-get update -qq && sudo apt-get install -y -qq ffmpeg libgl1 libglib2.0-0
          fi

      - name: Install Python dependencies
        run: |
          pip install uv
          uv pip install --system -r backend/requirements.txt

      - name: Run backend tests with coverage
        working-directory: backend
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: |
          pytest --splits 4 --group ${{ matrix.shard }} \
            --splitting-algorithm least_duration \
            --cov=app --cov-report=xml:coverage-shard${{ matrix.shard }}.xml \
            --cov-fail-under=0 -n auto --durations=10 --reruns 1 \
            -v --tb=short -q \
            --store-durations \
            tests/

      - name: Upload coverage artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: backend-coverage-shard${{ matrix.shard }}
          path: backend/coverage-shard${{ matrix.shard }}.xml
          retention-days: 1

  integration:
    name: Integration & Migration Tests
    runs-on: ubuntu-latest
    needs: [changes]
    if: needs.changes.outputs.backend == 'true'
    steps:
      - uses: actions/checkout@v6

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: "3.11"
          cache: pip
          cache-dependency-path: backend/requirements.txt

      - name: Start PostgreSQL
        run: |
          sudo systemctl start postgresql
          sudo -u postgres createuser -s test
          sudo -u postgres psql -c "ALTER USER test PASSWORD 'test';"
          sudo -u postgres createdb -O test test_sat

      - name: Start Redis
        run: |
          sudo apt-get install -y -qq redis-server
          redis-server --daemonize yes

      - name: Install system dependencies
        run: |
          for pkg in ffmpeg libgl1 libglib2.0-0; do
            dpkg -s "$pkg" >/dev/null 2>&1 || NEED_INSTALL=1
          done
          if [ "${NEED_INSTALL:-}" = "1" ]; then
            sudo apt-get update -qq && sudo apt-get install -y -qq ffmpeg libgl1 libglib2.0-0
          fi

      - name: Install Python dependencies
        run: |
          pip install uv
          uv pip install --system -r backend/requirements.txt

      - name: Run alembic migrations
        working-directory: backend
        env:
          DATABASE_URL: postgresql+psycopg2://test:test@localhost:5432/test_sat
        run: alembic upgrade head

      - name: Run integration tests
        working-directory: backend
        env:
          DATABASE_URL: postgresql+asyncpg://test:test@localhost:5432/test_sat
          REDIS_URL: redis://localhost:6379/0
          PYTHONPATH: ${{ github.workspace }}
        run: pytest -v --tb=short -m integration tests/test_integration.py --durations=10 --reruns 1

      - name: Run core processor tests
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: pytest satellite_processor/core/tests/ -v --tb=short --cov --cov-config=pyproject.toml --durations=10 --reruns 1 --cov-fail-under=0

  frontend:
    name: Frontend Tests (Shard ${{ matrix.shard }}/2)
    runs-on: ubuntu-latest
    needs: [changes]
    if: needs.changes.outputs.frontend == 'true'
    strategy:
      fail-fast: false
      matrix:
        shard: [1, 2]
    steps:
      - uses: actions/checkout@v6

      - name: Set up Node
        uses: actions/setup-node@v6
        with:
          node-version: "20"
          cache: npm
          cache-dependency-path: frontend/package-lock.json

      - name: Install dependencies
        working-directory: frontend
        run: npm ci

      - name: Lint
        if: matrix.shard == 1
        working-directory: frontend
        run: npm run lint

      - name: Unit Tests with coverage
        working-directory: frontend
        run: npx vitest run --coverage --shard=${{ matrix.shard }}/2

      - name: Upload coverage artifact
        if: matrix.shard == 1
        uses: actions/upload-artifact@v4
        with:
          name: frontend-coverage
          path: frontend/coverage/lcov.info
          retention-days: 1

  frontend-build:
    name: Frontend Build
    runs-on: ubuntu-latest
    needs: [changes]
    if: needs.changes.outputs.frontend == 'true'
    steps:
      - uses: actions/checkout@v6

      - name: Set up Node
        uses: actions/setup-node@v6
        with:
          node-version: "20"
          cache: npm
          cache-dependency-path: frontend/package-lock.json

      - name: Install dependencies
        working-directory: frontend
        run: npm ci

      - name: Build
        working-directory: frontend
        run: npm run build

      - name: Upload build artifact
        uses: actions/upload-artifact@v4
        with:
          name: frontend-build
          path: frontend/dist/
          retention-days: 1

  e2e:
    name: E2E Tests (Shard ${{ matrix.shard }}/2)
    runs-on: ubuntu-latest
    needs: [frontend-build]
    strategy:
      fail-fast: false
      matrix:
        shard: [1, 2]
        total: [2]
    steps:
      - uses: actions/checkout@v6

      - name: Set up Node
        uses: actions/setup-node@v6
        with:
          node-version: "20"
          cache: npm
          cache-dependency-path: frontend/package-lock.json

      - name: Cache node modules
        uses: actions/cache@v4
        with:
          path: frontend/node_modules
          key: node-modules-${{ hashFiles('frontend/package-lock.json') }}

      - name: Install dependencies
        working-directory: frontend
        run: npm ci

      - name: Download build artifact
        uses: actions/download-artifact@v4
        with:
          name: frontend-build
          path: frontend/dist/

      - name: Cache Playwright browsers
        id: playwright-cache
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: playwright-${{ hashFiles('frontend/package-lock.json') }}

      - name: Install Playwright Browsers
        working-directory: frontend
        run: npx playwright install --with-deps chromium

      - name: Run E2E tests
        working-directory: frontend
        run: npx playwright test --shard=${{ matrix.shard }}/${{ matrix.total }}
        env:
          CI: true

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-report-shard${{ matrix.shard }}
          path: frontend/playwright-report/
          retention-days: 7

      - name: Upload Playwright traces on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-traces-shard${{ matrix.shard }}
          path: frontend/test-results/
          retention-days: 7

  # Consolidate coverage from all shards + frontend and post PR summary
  pr-summary:
    name: PR Summary
    runs-on: ubuntu-latest
    needs: [changes, backend, frontend, frontend-build, e2e, integration, lint-audit]
    if: always() && github.event_name == 'pull_request'
    permissions:
      pull-requests: write
    steps:
      - uses: actions/checkout@v6

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: "3.11"

      - name: Download backend coverage shards
        if: needs.backend.result == 'success'
        uses: actions/download-artifact@v4
        with:
          pattern: backend-coverage-*
          path: backend/
          merge-multiple: true

      - name: Download frontend coverage
        if: needs.frontend.result == 'success'
        uses: actions/download-artifact@v4
        with:
          name: frontend-coverage
          path: frontend/coverage/

      - name: Merge backend coverage
        run: |
          if [ -f backend/coverage-shard1.xml ]; then
            cd backend
            python3 ../scripts/merge_coverage.py
            python3 -c "
          import xml.etree.ElementTree as ET
          root = ET.parse('coverage.xml').getroot()
          rate = root.get('line-rate', '0')
          print(round(float(rate) * 100, 1))
          " > coverage-total.txt 2>/dev/null || echo "0" > coverage-total.txt
            cat coverage-total.txt
          else
            echo "N/A" > backend/coverage-total.txt
          fi

      - name: Upload merged coverage
        if: needs.backend.result == 'success'
        uses: actions/upload-artifact@v4
        with:
          name: backend-coverage-merged
          path: backend/coverage.xml
          retention-days: 1

      - name: Post PR comment
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            // Read backend coverage
            let backendCov = 'N/A';
            try {
              backendCov = fs.readFileSync('backend/coverage-total.txt', 'utf8').trim();
              if (backendCov !== 'N/A') backendCov += '%';
            } catch {}

            // Read frontend coverage from lcov
            let frontendCov = 'N/A';
            try {
              const lcov = fs.readFileSync('frontend/coverage/lcov.info', 'utf8');
              const lf = (lcov.match(/^LF:(\d+)/gm) || []).reduce((s, l) => s + parseInt(l.split(':')[1]), 0);
              const lh = (lcov.match(/^LH:(\d+)/gm) || []).reduce((s, l) => s + parseInt(l.split(':')[1]), 0);
              frontendCov = lf > 0 ? (lh / lf * 100).toFixed(1) + '%' : 'N/A';
            } catch {}

            // Job results ‚Äî skipped jobs are OK when path-filtered
            const jobs = {
              backend: '${{ needs.backend.result }}',
              integration: '${{ needs.integration.result }}',
              frontend: '${{ needs.frontend.result }}',
              'frontend-build': '${{ needs.frontend-build.result }}',
              e2e: '${{ needs.e2e.result }}',
              'lint-audit': '${{ needs.lint-audit.result }}'
            };

            const icon = (r) => r === 'success' ? '‚úÖ' : r === 'skipped' ? '‚è≠Ô∏è' : '‚ùå';

            const body = `## ü§ñ CI Summary

            | Job | Status |
            |-----|--------|
            | Lint & Audit | ${icon(jobs['lint-audit'])} ${jobs['lint-audit']} |
            | Backend Tests (4 shards) | ${icon(jobs.backend)} ${jobs.backend} |
            | Integration & Migration | ${icon(jobs.integration)} ${jobs.integration} |
            | Frontend Tests (2 shards) | ${icon(jobs.frontend)} ${jobs.frontend} |
            | Frontend Build | ${icon(jobs['frontend-build'])} ${jobs['frontend-build']} |
            | E2E Tests | ${icon(jobs.e2e)} ${jobs.e2e} |

            ### üìä Coverage
            - **Backend:** ${backendCov}
            - **Frontend:** ${frontendCov}

            ---
            *Updated: ${new Date().toISOString()}*`;

            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number
            });

            const botComment = comments.find(c =>
              c.user.type === 'Bot' && c.body.includes('ü§ñ CI Summary')
            );

            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body
              });
            }

      - name: Check all jobs passed
        if: always()
        run: |
          # Skipped jobs are OK (path-filtered), only fail on actual failures
          check_job() {
            local result="$1"
            local name="$2"
            if [ "$result" != "success" ] && [ "$result" != "skipped" ]; then
              echo "‚ùå $name failed: $result"
              return 1
            fi
          }

          FAILED=0
          check_job "${{ needs.backend.result }}" "backend" || FAILED=1
          check_job "${{ needs.integration.result }}" "integration" || FAILED=1
          check_job "${{ needs.frontend.result }}" "frontend" || FAILED=1
          check_job "${{ needs.frontend-build.result }}" "frontend-build" || FAILED=1
          check_job "${{ needs.e2e.result }}" "e2e" || FAILED=1
          check_job "${{ needs.lint-audit.result }}" "lint-audit" || FAILED=1

          if [ "$FAILED" = "1" ]; then
            exit 1
          fi
          echo "‚úÖ All jobs passed (or were skipped due to path filters)"
